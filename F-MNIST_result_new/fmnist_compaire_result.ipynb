{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe02a92a",
   "metadata": {
    "executionInfo": {
     "elapsed": 9518,
     "status": "ok",
     "timestamp": 1756103855970,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "fe02a92a"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QEDzVWELaRoK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38974,
     "status": "ok",
     "timestamp": 1756103894936,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "QEDzVWELaRoK",
    "outputId": "d80a6757-3b05-4af2-e92d-37ffcedbc7b0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43487c6",
   "metadata": {
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1756103894975,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "d43487c6"
   },
   "outputs": [],
   "source": [
    "# Global variables\n",
    "root_path = \"/content/drive/MyDrive/Colab Notebooks/Federated Learning/Final_code/\"\n",
    "\n",
    "data_folder = root_path + \"F-MNIST_result_new\"\n",
    "dataset_name = \"Fashion - MNIST\"\n",
    "\n",
    "COLORS = {\n",
    "    'FedAdam': '#e74c3c',\n",
    "    'FedAvg': '#3498db',\n",
    "    'FedProx': '#27ae60'\n",
    "}\n",
    "\n",
    "def load_data(data_folder=data_folder, dataset_name=dataset_name):\n",
    "    \"\"\"\n",
    "    Load t·∫•t c·∫£ file JSON t·ª´ th∆∞ m·ª•c\n",
    "    Returns: dict containing loaded data\n",
    "    \"\"\"\n",
    "    data_folder = Path(data_folder)\n",
    "    data = {}\n",
    "\n",
    "    print(f\"üîÑ ƒêang load d·ªØ li·ªáu t·ª´ {data_folder}...\")\n",
    "\n",
    "    # ƒê·ªãnh nghƒ©a c√°c file c·∫ßn load\n",
    "    file_patterns = {\n",
    "\n",
    "        'FedAvg_0.3': ['alpha_03/FedAvg_fmnist_03.json', 'alpha_03/FedAvg_cifar10_03.json'],\n",
    "        'FedProx_0.3': ['alpha_03/FedProx_fmnist_03.json', 'alpha_03/FedProx_cifar10_03.json'],\n",
    "        'FedAdam_0.3': ['alpha_03/FedAdam_fmnist_03.json', 'alpha_03/FedAdam_cifar10_03.json'],\n",
    "\n",
    "        'FedAvg_0.9': ['alpha_09/FedAvg_fmnist_09.json', 'alpha_09/FedAvg_cifar10_09.json'],\n",
    "        'FedProx_0.9': ['alpha_09/FedProx_fmnist_09.json', 'alpha_09/FedProx_cifar10_09.json'],\n",
    "        'FedAdam_0.9': ['alpha_09/FedAdam_fmnist_09.json', 'alpha_09/FedAdam_cifar10_09.json'],\n",
    "    }\n",
    "\n",
    "    loaded_count = 0\n",
    "    dataset_suffix = 'fmnist' if 'MNIST' in dataset_name else 'cifar10'\n",
    "\n",
    "    for key, patterns in file_patterns.items():\n",
    "        # Ch·ªçn pattern ph√π h·ª£p v·ªõi dataset\n",
    "        pattern = patterns[0] if 'fmnist' in patterns[0] else patterns[1]\n",
    "        if dataset_suffix not in pattern:\n",
    "            pattern = patterns[1] if dataset_suffix == 'cifar10' else patterns[0]\n",
    "\n",
    "        file_path = data_folder / pattern\n",
    "\n",
    "        if file_path.exists():\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data_content = json.load(f)\n",
    "\n",
    "                # Parse th√¥ng tin t·ª´ key\n",
    "                parts = key.split('_')\n",
    "                algorithm = parts[0]\n",
    "                alpha = float(parts[1])\n",
    "\n",
    "                data[key] = {\n",
    "                    'algorithm': algorithm,\n",
    "                    'alpha': alpha,\n",
    "                    'metrics': data_content['metrics'],\n",
    "                    'strategy_name': data_content.get('strategy_name', algorithm)\n",
    "                }\n",
    "                loaded_count += 1\n",
    "                print(f\"‚úÖ Loaded: {file_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå L·ªói load {file_path}: {e}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y: {file_path}\")\n",
    "\n",
    "    print(f\"üéâ ƒê√£ load th√†nh c√¥ng {loaded_count}/6 files cho {dataset_name}\")\n",
    "    return data if loaded_count > 0 else None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e79de8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5179,
     "status": "ok",
     "timestamp": 1756103900111,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "e7e79de8",
    "outputId": "bceb10a5-7c86-4ec6-af68-5e77016b6642"
   },
   "outputs": [],
   "source": [
    "data = load_data(data_folder= data_folder, dataset_name= dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f830e51f",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1756103900123,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "f830e51f"
   },
   "outputs": [],
   "source": [
    "def create_summary_stats(data, dataset_name=dataset_name):\n",
    "    \"\"\"T·∫°o th·ªëng k√™ t·ªïng quan\"\"\"\n",
    "    if not data:\n",
    "        print(\"‚ùå Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch!\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüìä TH·ªêNG K√ä T·ªîNG QUAN - {dataset_name}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    for key, data_item in data.items():\n",
    "        metrics = data_item['metrics']\n",
    "        final_train_acc = metrics[-1]['train_acc'] * 100\n",
    "        final_val_acc = metrics[-1].get('val_acc', 0) * 100\n",
    "        total_time_hours = sum(m.get('round_total_time', 0) for m in metrics) / 3600\n",
    "\n",
    "        print(f\"\\n{data_item['algorithm']} (Œ±={data_item['alpha']}):\")\n",
    "        print(f\"  üìà Final Train Acc: {final_train_acc:.2f}%\")\n",
    "        print(f\"  üéØ Final Val Acc: {final_val_acc:.2f}%\")\n",
    "        print(f\"  ‚è±Ô∏è  Total Time: {total_time_hours:.2f} hours\")\n",
    "        print(f\"  üîÑ Total Rounds: {len(metrics)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6f49c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1756103900154,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "3db6f49c",
    "outputId": "135d34fd-fe46-440d-ba5a-4634a75b1950"
   },
   "outputs": [],
   "source": [
    "print(f\"\\nüöÄ B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH FEDERATED LEARNING - {dataset_name}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Th·ªëng k√™ t·ªïng quan\n",
    "create_summary_stats(data, dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf13b4",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1756103900175,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "33bf13b4"
   },
   "outputs": [],
   "source": [
    "def plot_individual_results(data, dataset_name=dataset_name):\n",
    "    \"\"\"1. Tr·ª±c quan k·∫øt qu·∫£ t·ª´ng thu·∫≠t to√°n\"\"\"\n",
    "    if not data:\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(f'K·∫øt qu·∫£ t·ª´ng thu·∫≠t to√°n - {dataset_name}', fontsize=16, fontweight='bold')\n",
    "\n",
    "    algorithms = ['FedAvg', 'FedProx', 'FedAdam']\n",
    "\n",
    "    for i, algorithm in enumerate(algorithms):\n",
    "        # Training metrics\n",
    "        ax1 = axes[0, i]\n",
    "        ax2 = ax1.twinx()\n",
    "\n",
    "        for alpha in [0.3, 0.9]:\n",
    "            key = f\"{algorithm}_{alpha}\"\n",
    "            if key in data:\n",
    "                metrics = data[key]['metrics']\n",
    "                # Fix: Use safer data access with enumerate\n",
    "                rounds = [m.get('round', i+1) for i, m in enumerate(metrics)]\n",
    "                train_acc = [m['train_acc'] * 100 for m in metrics]\n",
    "                train_loss = [m['train_loss'] for m in metrics]\n",
    "\n",
    "                # Plot accuracy\n",
    "                line1 = ax1.plot(rounds, train_acc, '-',\n",
    "                               label=f'Train Acc Œ±={alpha}',\n",
    "                               color=COLORS[algorithm],\n",
    "                               alpha=0.8 if alpha == 0.3 else 0.5,\n",
    "                               linewidth=2)\n",
    "\n",
    "                # Plot loss\n",
    "                line2 = ax2.plot(rounds, train_loss, '--',\n",
    "                               label=f'Train Loss Œ±={alpha}',\n",
    "                               color=COLORS[algorithm],\n",
    "                               alpha=0.6 if alpha == 0.3 else 0.3,\n",
    "                               linewidth=2)\n",
    "\n",
    "        ax1.set_xlabel('Round')\n",
    "        ax1.set_ylabel('Training Accuracy (%)', color='black')\n",
    "        ax2.set_ylabel('Training Loss', color='gray')\n",
    "        ax1.set_title(f'{algorithm} - Training Metrics')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "        # Validation metrics\n",
    "        ax3 = axes[1, i]\n",
    "        ax4 = ax3.twinx()\n",
    "\n",
    "        for alpha in [0.3, 0.9]:\n",
    "            key = f\"{algorithm}_{alpha}\"\n",
    "            if key in data:\n",
    "                metrics = data[key]['metrics']\n",
    "                # Fix: Use safer data access with enumerate\n",
    "                rounds = [m.get('round', i+1) for i, m in enumerate(metrics)]\n",
    "                val_acc = [m.get('val_acc', 0) * 100 for m in metrics]\n",
    "                val_loss = [m.get('val_loss', 0) for m in metrics]\n",
    "\n",
    "                ax3.plot(rounds, val_acc, '-',\n",
    "                       label=f'Val Acc Œ±={alpha}',\n",
    "                       color=COLORS[algorithm],\n",
    "                       alpha=0.8 if alpha == 0.3 else 0.5,\n",
    "                       linewidth=2)\n",
    "\n",
    "                ax4.plot(rounds, val_loss, '--',\n",
    "                       label=f'Val Loss Œ±={alpha}',\n",
    "                       color=COLORS[algorithm],\n",
    "                       alpha=0.6 if alpha == 0.3 else 0.3,\n",
    "                       linewidth=2)\n",
    "\n",
    "        ax3.set_xlabel('Round')\n",
    "        ax3.set_ylabel('Validation Accuracy (%)', color='black')\n",
    "        ax4.set_ylabel('Validation Loss', color='gray')\n",
    "        ax3.set_title(f'{algorithm} - Validation Metrics')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "\n",
    "        ax1.legend(loc='center right')\n",
    "        ax2.legend(loc='upper right', bbox_to_anchor=(1.01, 0.4))\n",
    "        ax3.legend(loc='center right')\n",
    "        ax4.legend(loc='upper right', bbox_to_anchor=(1.01, 0.4))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'individual_results_{dataset_name.lower().replace(\"-\", \"_\")}.png',\n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7685e2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 919
    },
    "executionInfo": {
     "elapsed": 6270,
     "status": "ok",
     "timestamp": 1756103906448,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "e7685e2e",
    "outputId": "fa110d79-6dde-49cc-ddfa-702512f552f3"
   },
   "outputs": [],
   "source": [
    "# 2. C√°c bi·ªÉu ƒë·ªì ph√¢n t√≠ch\n",
    "print(\"\\nüìä ƒêang t·∫°o bi·ªÉu ƒë·ªì...\")\n",
    "plot_individual_results(data, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ym2GpGvZNiP6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7817,
     "status": "ok",
     "timestamp": 1756103914270,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "ym2GpGvZNiP6",
    "outputId": "10217d18-56f8-4b4e-b916-4f2cf361bbbb"
   },
   "outputs": [],
   "source": [
    "def plot_individual_algorithm_metrics(data, dataset_name=dataset_name):\n",
    "    \"\"\"\n",
    "    Tr·ª±c quan chi ti·∫øt t·ª´ng thu·∫≠t to√°n v·ªõi 4 metric ri√™ng bi·ªát\n",
    "    M·ªói thu·∫≠t to√°n s·∫Ω c√≥ 1 figure v·ªõi 4 subplot: train_acc, train_loss, val_acc, val_loss\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        print(\"‚ùå Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch!\")\n",
    "        return\n",
    "\n",
    "    algorithms = ['FedAvg', 'FedProx', 'FedAdam']\n",
    "\n",
    "    for algorithm in algorithms:\n",
    "        # T·∫°o figure cho t·ª´ng thu·∫≠t to√°n\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig.suptitle(f'Chi ti·∫øt metrics cho {algorithm} - {dataset_name}',\n",
    "                     fontsize=16, fontweight='bold')\n",
    "\n",
    "        # Define metrics and their corresponding subplot positions\n",
    "        metrics_config = [\n",
    "            ('train_acc', 'Training Accuracy (%)', axes[0, 0], True),  # True means convert to percentage\n",
    "            ('train_loss', 'Training Loss', axes[0, 1], False),\n",
    "            ('val_acc', 'Validation Accuracy (%)', axes[1, 0], True),\n",
    "            ('val_loss', 'Validation Loss', axes[1, 1], False)\n",
    "        ]\n",
    "\n",
    "        for metric_key, ylabel, ax, to_percentage in metrics_config:\n",
    "            for alpha in [0.3, 0.9]:\n",
    "                key = f\"{algorithm}_{alpha}\"\n",
    "                if key in data:\n",
    "                    metrics = data[key]['metrics']\n",
    "                    rounds = [m.get('round', i+1) for i, m in enumerate(metrics)]\n",
    "\n",
    "                    # Get metric values\n",
    "                    if to_percentage:\n",
    "                        values = [m.get(metric_key, 0) * 100 for m in metrics]\n",
    "                    else:\n",
    "                        values = [m.get(metric_key, 0) for m in metrics]\n",
    "\n",
    "                    # Plot with different styles for different alphas\n",
    "                    linestyle = '-' if alpha == 0.3 else '--'\n",
    "                    alpha_opacity = 0.8 if alpha == 0.3 else 0.6\n",
    "                    linewidth = 2.5 if alpha == 0.3 else 2\n",
    "\n",
    "                    ax.plot(rounds, values, linestyle,\n",
    "                           label=f'Œ± = {alpha}',\n",
    "                           color=COLORS[algorithm],\n",
    "                           linewidth=linewidth)\n",
    "\n",
    "            # Customize subplot\n",
    "            ax.set_xlabel('Round', fontsize=12)\n",
    "            ax.set_ylabel(ylabel, fontsize=12)\n",
    "            ax.set_title(f'{algorithm} - {ylabel}', fontsize=14)\n",
    "            ax.legend(fontsize=11)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "            # Add some styling\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "\n",
    "            # Set y-axis limits for better visualization\n",
    "            if 'acc' in metric_key.lower() and to_percentage:\n",
    "                ax.set_ylim(0, 100)\n",
    "            elif 'loss' in metric_key.lower():\n",
    "                # For loss, set a reasonable upper limit\n",
    "                max_val = max([m.get(metric_key, 0) for m in data[f\"{algorithm}_0.3\"]['metrics']] +\n",
    "                            [m.get(metric_key, 0) for m in data[f\"{algorithm}_0.9\"]['metrics']]\n",
    "                            if f\"{algorithm}_0.3\" in data and f\"{algorithm}_0.9\" in data else [1])\n",
    "                ax.set_ylim(0, max_val * 1.1)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{algorithm.lower()}_detailed_metrics_{dataset_name.lower().replace(\"-\", \"_\")}.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        # Print summary statistics for this algorithm\n",
    "        print(f\"\\nüìä TH·ªêNG K√ä CHI TI·∫æT CHO {algorithm}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        for alpha in [0.3, 0.9]:\n",
    "            key = f\"{algorithm}_{alpha}\"\n",
    "            if key in data:\n",
    "                metrics = data[key]['metrics']\n",
    "                last_20 = metrics[-20:] if len(metrics) >= 20 else metrics\n",
    "\n",
    "                final_train_acc = metrics[-1]['train_acc'] * 100\n",
    "                final_val_acc = metrics[-1].get('val_acc', 0) * 100\n",
    "                final_train_loss = metrics[-1]['train_loss']\n",
    "                final_val_loss = metrics[-1].get('val_loss', 0)\n",
    "\n",
    "                avg_train_acc = np.mean([m['train_acc'] for m in last_20]) * 100\n",
    "                avg_val_acc = np.mean([m.get('val_acc', 0) for m in last_20]) * 100\n",
    "\n",
    "                print(f\"Œ± = {alpha}:\")\n",
    "                print(f\"  üìà Final Train Acc: {final_train_acc:.2f}% | Avg (20 rounds): {avg_train_acc:.2f}%\")\n",
    "                print(f\"  üéØ Final Val Acc: {final_val_acc:.2f}% | Avg (20 rounds): {avg_val_acc:.2f}%\")\n",
    "                print(f\"  üìâ Final Train Loss: {final_train_loss:.4f}\")\n",
    "                print(f\"  üìâ Final Val Loss: {final_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "def plot_comparative_summary(data, dataset_name=dataset_name):\n",
    "    \"\"\"\n",
    "    Bi·ªÉu ƒë·ªì t·ªïng quan so s√°nh t·∫•t c·∫£ thu·∫≠t to√°n tr√™n 4 metrics ch√≠nh\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "    fig.suptitle(f'So s√°nh t·ªïng quan t·∫•t c·∫£ thu·∫≠t to√°n - {dataset_name}',\n",
    "                 fontsize=18, fontweight='bold')\n",
    "\n",
    "    algorithms = ['FedAvg', 'FedProx', 'FedAdam']\n",
    "    metrics_config = [\n",
    "        ('train_acc', 'Training Accuracy (%)', axes[0, 0], True),\n",
    "        ('train_loss', 'Training Loss', axes[0, 1], False),\n",
    "        ('val_acc', 'Validation Accuracy (%)', axes[1, 0], True),\n",
    "        ('val_loss', 'Validation Loss', axes[1, 1], False)\n",
    "    ]\n",
    "\n",
    "    for metric_key, ylabel, ax, to_percentage in metrics_config:\n",
    "        for algorithm in algorithms:\n",
    "            for alpha in [0.3, 0.9]:\n",
    "                key = f\"{algorithm}_{alpha}\"\n",
    "                if key in data:\n",
    "                    metrics = data[key]['metrics']\n",
    "                    rounds = [m.get('round', i+1) for i, m in enumerate(metrics)]\n",
    "\n",
    "                    if to_percentage:\n",
    "                        values = [m.get(metric_key, 0) * 100 for m in metrics]\n",
    "                    else:\n",
    "                        values = [m.get(metric_key, 0) for m in metrics]\n",
    "\n",
    "                    linestyle = '-' if alpha == 0.3 else '--'\n",
    "                    alpha_opacity = 0.8 if alpha == 0.3 else 0.5\n",
    "\n",
    "                    ax.plot(rounds, values, linestyle,\n",
    "                           label=f'{algorithm} Œ±={alpha}',\n",
    "                           color=COLORS[algorithm],\n",
    "                           alpha=alpha_opacity,\n",
    "                           linewidth=2)\n",
    "\n",
    "        ax.set_xlabel('Round', fontsize=12)\n",
    "        ax.set_ylabel(ylabel, fontsize=12)\n",
    "        ax.set_title(ylabel, fontsize=14, fontweight='bold')\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Styling\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'comparative_summary_{dataset_name.lower().replace(\"-\", \"_\")}.png',\n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Th√™m c√°c h√†m m·ªõi v√†o ph·∫ßn ch√≠nh c·ªßa code\n",
    "print(\"\\nüé® ƒêang t·∫°o bi·ªÉu ƒë·ªì chi ti·∫øt cho t·ª´ng thu·∫≠t to√°n...\")\n",
    "plot_individual_algorithm_metrics(data, dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b119d",
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1756103914308,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "a25b119d"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_comparison_by_alpha(data, dataset_name=dataset_name):\n",
    "    \"\"\"2. So s√°nh k·∫øt qu·∫£ theo ƒë·ªô alpha\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(f'So s√°nh k·∫øt qu·∫£ theo Alpha - {dataset_name}', fontsize=16, fontweight='bold')\n",
    "\n",
    "    for alpha_idx, alpha in enumerate([0.3, 0.9]):\n",
    "        # Training Accuracy\n",
    "        ax1 = axes[0, alpha_idx]\n",
    "        # Validation Accuracy\n",
    "        ax2 = axes[1, alpha_idx]\n",
    "\n",
    "        for algorithm in ['FedAvg', 'FedProx', 'FedAdam']:\n",
    "            key = f\"{algorithm}_{alpha}\"\n",
    "            if key in data:\n",
    "                metrics = data[key]['metrics']\n",
    "                # Fix: Use safer data access with enumerate\n",
    "                rounds = [m.get('round', i+1) for i, m in enumerate(metrics)]\n",
    "                train_acc = [m['train_acc'] * 100 for m in metrics]\n",
    "                val_acc = [m.get('val_acc', 0) * 100 for m in metrics]\n",
    "\n",
    "                ax1.plot(rounds, train_acc, '-', label=algorithm,\n",
    "                       color=COLORS[algorithm], linewidth=2, marker='o', markersize=3)\n",
    "                ax2.plot(rounds, val_acc, '-', label=algorithm,\n",
    "                       color=COLORS[algorithm], linewidth=2, marker='s', markersize=3)\n",
    "\n",
    "        ax1.set_title(f'Training Accuracy (Œ±={alpha})')\n",
    "        ax1.set_xlabel('Round')\n",
    "        ax1.set_ylabel('Accuracy (%)')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        ax2.set_title(f'Validation Accuracy (Œ±={alpha})')\n",
    "        ax2.set_xlabel('Round')\n",
    "        ax2.set_ylabel('Accuracy (%)')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'comparison_by_alpha_{dataset_name.lower().replace(\"-\", \"_\")}.png',\n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9b8bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 994
    },
    "executionInfo": {
     "elapsed": 2676,
     "status": "ok",
     "timestamp": 1756103916993,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "46f9b8bd",
    "outputId": "f218640e-02d5-404a-b945-cbb200130921"
   },
   "outputs": [],
   "source": [
    "plot_comparison_by_alpha(data, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020mcOT1eqCB",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1756103916999,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "020mcOT1eqCB"
   },
   "outputs": [],
   "source": [
    "def format_time(seconds):\n",
    "    \"\"\"Chuy·ªÉn ƒë·ªïi gi√¢y th√†nh ƒë·ªãnh d·∫°ng th·ªùi gian d·ªÖ ƒë·ªçc\"\"\"\n",
    "    if seconds < 60:\n",
    "        return f\"{seconds:.1f}s\"\n",
    "    elif seconds < 3600:\n",
    "        minutes = seconds / 60\n",
    "        return f\"{minutes:.1f} ph√∫t\"\n",
    "    else:\n",
    "        hours = seconds / 3600\n",
    "        return f\"{hours:.2f} gi·ªù\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20df61c",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1756103917007,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "e20df61c"
   },
   "outputs": [],
   "source": [
    "def plot_time_comparison(data, dataset_name=dataset_name):\n",
    "    \"\"\"3. So s√°nh th·ªùi gian training - ƒê√É S·ª¨A ƒê·ªÇ HI·ªÇN TH·ªä ƒê√öNG TH·ªúI GIAN\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12)) # Changed from 2, 2 to 3, 2\n",
    "    fig.suptitle(f'So s√°nh th·ªùi gian Training - {dataset_name}', fontsize=16, fontweight='bold')\n",
    "\n",
    "    for alpha_idx, alpha in enumerate([0.3, 0.9]):\n",
    "        # Th·ªùi gian m·ªói round (gi√¢y)\n",
    "        ax1 = axes[0, alpha_idx]\n",
    "        # Th·ªùi gian t√≠ch l≈©y (gi·ªù)\n",
    "        ax2 = axes[1, alpha_idx]\n",
    "\n",
    "        for algorithm in ['FedAvg', 'FedProx', 'FedAdam']:\n",
    "            key = f\"{algorithm}_{alpha}\"\n",
    "            if key in data:\n",
    "                metrics = data[key]['metrics']\n",
    "                # Fix: Use safer data access with enumerate\n",
    "                rounds = [m.get('round', i+1) for i, m in enumerate(metrics)]\n",
    "                round_times_seconds = [m.get('round_total_time', 0) for m in metrics]  # Gi·ªØ nguy√™n gi√¢y\n",
    "                cumulative_times_hours = np.cumsum(round_times_seconds) / 3600  # Chuy·ªÉn th√†nh gi·ªù\n",
    "\n",
    "                # Plot th·ªùi gian m·ªói round (gi√¢y)\n",
    "                ax1.plot(rounds, round_times_seconds, '-', label=algorithm,\n",
    "                       color=COLORS[algorithm], linewidth=2, alpha=0.7)\n",
    "\n",
    "                # Plot th·ªùi gian t√≠ch l≈©y (gi·ªù)\n",
    "                ax2.plot(rounds, cumulative_times_hours, '-', label=algorithm,\n",
    "                       color=COLORS[algorithm], linewidth=2, marker='o', markersize=3)\n",
    "\n",
    "        ax1.set_title(f'Th·ªùi gian m·ªói Round (Œ±={alpha})')\n",
    "        ax1.set_xlabel('Round')\n",
    "        ax1.set_ylabel('Th·ªùi gian (gi√¢y)')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        ax2.set_title(f'Th·ªùi gian t√≠ch l≈©y (Œ±={alpha})')\n",
    "        ax2.set_xlabel('Round')\n",
    "        ax2.set_ylabel('T·ªïng th·ªùi gian (gi·ªù)')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # 2. Bi·ªÉu ƒë·ªì th·ªùi gian trung b√¨nh m·ªói round (ph√∫t)\n",
    "    algorithms = ['FedAdam', 'FedAvg', 'FedProx']\n",
    "    width = 0.5  # tƒÉng chi·ªÅu r·ªông c·ªôt cho s√°t nhau h∆°n\n",
    "\n",
    "    # L·∫•y th·ªùi gian trung b√¨nh m·ªói round theo ph√∫t\n",
    "    avg_times_03 = []\n",
    "    avg_times_09 = []\n",
    "\n",
    "    for algorithm in algorithms:\n",
    "        key_03 = f\"{algorithm}_0.3\"\n",
    "        key_09 = f\"{algorithm}_0.9\"\n",
    "\n",
    "        time_03 = np.mean([\n",
    "            m.get('round_total_time', 0) for m in data.get(key_03, {}).get('metrics', [])\n",
    "        ]) / 60 if key_03 in data else 0\n",
    "\n",
    "        time_09 = np.mean([\n",
    "            m.get('round_total_time', 0) for m in data.get(key_09, {}).get('metrics', [])\n",
    "        ]) / 60 if key_09 in data else 0\n",
    "\n",
    "        avg_times_03.append((algorithm, time_03))\n",
    "        avg_times_09.append((algorithm, time_09))\n",
    "\n",
    "    # S·∫Øp x·∫øp gi·∫£m d·∫ßn theo th·ªùi gian\n",
    "    avg_times_03.sort(key=lambda x: x[1], reverse=True)\n",
    "    avg_times_09.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # T√°ch l·∫°i d·ªØ li·ªáu sau khi s·∫Øp\n",
    "    algos_03, times_03 = zip(*avg_times_03)\n",
    "    algos_09, times_09 = zip(*avg_times_09)\n",
    "    x_03 = np.arange(len(algos_03))\n",
    "    x_09 = np.arange(len(algos_09))\n",
    "\n",
    "    # T·∫°o bi·ªÉu ƒë·ªì\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "    fig.suptitle('Th·ªùi gian trung b√¨nh m·ªói Round theo Alpha', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Bi·ªÉu ƒë·ªì Œ± = 0.3\n",
    "    bars1 = axes[0].bar(x_03, times_03, width, label='Œ±=0.3', color='#3498db', alpha=0.85)\n",
    "    axes[0].set_title('Œ± = 0.3', fontsize=14)\n",
    "    axes[0].set_xlabel('Thu·∫≠t to√°n', fontsize=12)\n",
    "    axes[0].set_ylabel('Th·ªùi gian (ph√∫t)', fontsize=12)\n",
    "    axes[0].set_xticks(x_03)\n",
    "    axes[0].set_xticklabels(algos_03)\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    for i, bar in enumerate(bars1):\n",
    "        height = bar.get_height()\n",
    "        axes[0].text(bar.get_x() + bar.get_width() / 2, height + 0.05,\n",
    "                    f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    # Bi·ªÉu ƒë·ªì Œ± = 0.9\n",
    "    bars2 = axes[1].bar(x_09, times_09, width, label='Œ±=0.9', color='#e74c3c', alpha=0.85)\n",
    "    axes[1].set_title('Œ± = 0.9', fontsize=14)\n",
    "    axes[1].set_xlabel('Thu·∫≠t to√°n', fontsize=12)\n",
    "    axes[1].set_xticks(x_09)\n",
    "    axes[1].set_xticklabels(algos_09)\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    for i, bar in enumerate(bars2):\n",
    "        height = bar.get_height()\n",
    "        axes[1].text(bar.get_x() + bar.get_width() / 2, height + 0.05,\n",
    "                    f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    # Y-axis ƒë·ªìng b·ªô v√† th·∫©m m·ªπ\n",
    "    y_min = min(min(times_03), min(times_09)) - 0.1\n",
    "    y_max = max(max(times_03), max(times_09)) + 0.3\n",
    "    axes[0].set_ylim(y_min, y_max)\n",
    "    axes[1].set_ylim(y_min, y_max)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b87b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1606,
     "status": "ok",
     "timestamp": 1756103918617,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "3c3b87b8",
    "outputId": "1c9595ff-24cb-46cb-882d-520b4ee61365"
   },
   "outputs": [],
   "source": [
    "plot_time_comparison(data, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3ac0c",
   "metadata": {
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1756104288104,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "57f3ac0c"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "COLORS = {\n",
    "    'FedAvg': '#3498db',\n",
    "    'FedProx': '#27ae60',\n",
    "    'FedAdam': '#e74c3c',\n",
    "}\n",
    "\n",
    "def create_final_stats_table(data, dataset_name=\"\"):\n",
    "    \"\"\"In b·∫£ng th·ªëng k√™ v√† v·∫Ω bi·ªÉu ƒë·ªì c·ªôt + line Accuracy\"\"\"\n",
    "    if not data:\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüéØ K·∫æT QU·∫¢ TRUNG B√åNH 20 ROUND CU·ªêI - {dataset_name}\")\n",
    "    print(\"=\" * 90)\n",
    "\n",
    "    results = []\n",
    "    for key, data_item in data.items():\n",
    "        metrics = data_item['metrics']\n",
    "        last_20 = metrics[-20:] if len(metrics) >= 20 else metrics\n",
    "\n",
    "        avg_train_acc = np.mean([m['train_acc'] for m in last_20]) * 100\n",
    "        avg_val_acc = np.mean([m.get('val_acc', 0) for m in last_20]) * 100\n",
    "        avg_train_loss = np.mean([m['train_loss'] for m in last_20])\n",
    "        avg_val_loss = np.mean([m.get('val_loss', 0) for m in last_20])\n",
    "        total_time = sum([m.get('round_total_time', 0) for m in metrics]) / 3600\n",
    "\n",
    "        results.append({\n",
    "            'Algorithm': data_item['strategy_name'],\n",
    "            'Alpha': data_item['alpha'],\n",
    "            'Train Acc (%)': avg_train_acc,\n",
    "            'Val Acc (%)': avg_val_acc,\n",
    "            'Train Loss': avg_train_loss,\n",
    "            'Val Loss': avg_val_loss,\n",
    "            'Total Time (h)': total_time\n",
    "        })\n",
    "\n",
    "    # In b·∫£ng k·∫øt qu·∫£\n",
    "    for res in results:\n",
    "        print(f\"{res['Algorithm']:10s} | Œ±={res['Alpha']} | \"\n",
    "              f\"Val Acc: {res['Val Acc (%)']:.2f}% | \"\n",
    "              f\"Train Acc: {res['Train Acc (%)']:.2f}% | \"\n",
    "              f\"Val Loss: {res['Val Loss']:.4f} | \"\n",
    "              f\"Train Loss: {res['Train Loss']:.4f} | \"\n",
    "              f\"Time: {res['Total Time (h)']:.2f}h\")\n",
    "\n",
    "\n",
    "    algorithms = [ 'FedProx', 'FedAdam', 'FedAvg']\n",
    "    x = np.arange(len(algorithms))\n",
    "\n",
    "    val_acc_03 = []\n",
    "    val_acc_09 = []\n",
    "\n",
    "    for algo in algorithms:\n",
    "        val_acc_03.append(next(r['Val Acc (%)'] for r in results if r['Algorithm'] == algo and r['Alpha'] == 0.3))\n",
    "        val_acc_09.append(next(r['Val Acc (%)'] for r in results if r['Algorithm'] == algo and r['Alpha'] == 0.9))\n",
    "\n",
    "    # üé® Bi·ªÉu ƒë·ªì c·ªôt so s√°nh Val Accuracy\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    algorithms = list(set([r['Algorithm'] for r in results]))\n",
    "    x = np.arange(len(algorithms))\n",
    "    width = 0.35\n",
    "\n",
    "    alpha_03_scores = val_acc_03\n",
    "    alpha_09_scores = val_acc_09\n",
    "\n",
    "    bars1 = ax1.bar(x - width/2, alpha_03_scores, width, label='Œ±=0.3', color='#3498db', alpha=0.8)\n",
    "    bars2 = ax1.bar(x + width/2, alpha_09_scores, width, label='Œ±=0.9', color='#e74c3c', alpha=0.8)\n",
    "\n",
    "    ax1.set_title(f'So s√°nh Val Accuracy - {dataset_name}')\n",
    "    ax1.set_xlabel('Thu·∫≠t to√°n')\n",
    "    ax1.set_ylabel('Validation Accuracy (%)')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(algorithms)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # Ghi s·ªë l√™n c·ªôt\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                     f'{height:.2f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # üé® Bi·ªÉu ƒë·ªì line: So s√°nh Val Accuracy theo thu·∫≠t to√°n (t·ª´ng alpha)\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    ax.plot(x, val_acc_03, '-o', color='#3498db', label='Œ±=0.3')\n",
    "    ax.plot(x, val_acc_09, '-o', color='#e74c3c', label='Œ±=0.9')\n",
    "\n",
    "    # Annotate\n",
    "    for i in range(len(x)):\n",
    "        ax.text(x[i], val_acc_03[i] + 0.5, f\"{val_acc_03[i]:.2f}\", fontsize=9)\n",
    "        ax.text(x[i], val_acc_09[i] + 0.5, f\"{val_acc_09[i]:.2f}\", fontsize=9)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(algorithms)\n",
    "    ax.set_xlabel('Thu·∫≠t to√°n')\n",
    "    ax.set_ylabel('Validation Accuracy (%)')\n",
    "    ax.set_title(f'{dataset_name}')\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Adjust y-axis limits to accommodate annotations\n",
    "    y_min = min(min(val_acc_03), min(val_acc_09)) - 1.5\n",
    "    y_max = max(max(val_acc_03), max(val_acc_09)) + 1.5\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c790339",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 650,
     "status": "ok",
     "timestamp": 1756104288804,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "5c790339",
    "outputId": "8b062e28-0c3c-46ed-8c3f-57990c7e8eca"
   },
   "outputs": [],
   "source": [
    "create_final_stats_table(data, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02110c2e",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756103918704,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "02110c2e"
   },
   "outputs": [],
   "source": [
    "def plot_additional_analysis(data, dataset_name=dataset_name):\n",
    "    \"\"\"5. C√°c bi·ªÉu ƒë·ªì ph√¢n t√≠ch b·ªï sung\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(f'Ph√¢n t√≠ch b·ªï sung - {dataset_name}', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # 1. Convergence Rate (t·ªëc ƒë·ªô h·ªôi t·ª•)\n",
    "    ax1 = axes[0, 0]\n",
    "    for alpha in [0.3, 0.9]:\n",
    "        for algorithm in ['FedAvg', 'FedProx', 'FedAdam']:\n",
    "            key = f\"{algorithm}_{alpha}\"\n",
    "            if key in data:\n",
    "                metrics = data[key]['metrics']\n",
    "                val_acc = [m.get('val_acc', 0) * 100 for m in metrics]\n",
    "                # T√≠nh ƒë·ªô c·∫£i thi·ªán so v·ªõi round tr∆∞·ªõc\n",
    "                improvements = [val_acc[i] - val_acc[i-1] for i in range(1, len(val_acc))]\n",
    "                # Fix: Use safer data access with enumerate\n",
    "                rounds = [m.get('round', i+1) for i, m in enumerate(metrics[1:])]\n",
    "\n",
    "                linestyle = '-' if alpha == 0.3 else '--'\n",
    "                ax1.plot(rounds, improvements, linestyle,\n",
    "                       label=f'{algorithm} Œ±={alpha}',\n",
    "                       color=COLORS[algorithm], alpha=0.7)\n",
    "\n",
    "    ax1.set_title('T·ªëc ƒë·ªô h·ªôi t·ª• (Validation Accuracy)')\n",
    "    ax1.set_xlabel('Round')\n",
    "    ax1.set_ylabel('C·∫£i thi·ªán Accuracy (%)')\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "\n",
    "    # 2. Performance comparison (Bar chart)\n",
    "    ax2 = axes[0, 1]\n",
    "    algorithms = ['FedAvg', 'FedProx', 'FedAdam']\n",
    "    alpha_03_scores = []\n",
    "    alpha_09_scores = []\n",
    "\n",
    "    for algorithm in algorithms:\n",
    "        score_03 = 0\n",
    "        score_09 = 0\n",
    "\n",
    "        key_03 = f\"{algorithm}_0.3\"\n",
    "        key_09 = f\"{algorithm}_0.9\"\n",
    "\n",
    "        if key_03 in data:\n",
    "            last_20 = data[key_03]['metrics'][-20:]\n",
    "            score_03 = np.mean([m.get('val_acc', 0) for m in last_20]) * 100\n",
    "\n",
    "        if key_09 in data:\n",
    "            last_20 = data[key_09]['metrics'][-20:]\n",
    "            score_09 = np.mean([m.get('val_acc', 0) for m in last_20]) * 100\n",
    "\n",
    "        alpha_03_scores.append(score_03)\n",
    "        alpha_09_scores.append(score_09)\n",
    "\n",
    "    x = np.arange(len(algorithms))\n",
    "    width = 0.35\n",
    "\n",
    "    bars1 = ax2.bar(x - width/2, alpha_03_scores, width, label='Œ±=0.3', color='#3498db', alpha=0.8)\n",
    "    bars2 = ax2.bar(x + width/2, alpha_09_scores, width, label='Œ±=0.9', color='#e74c3c', alpha=0.8)\n",
    "\n",
    "    ax2.set_title('So s√°nh hi·ªáu su·∫•t cu·ªëi c√πng')\n",
    "    ax2.set_xlabel('Thu·∫≠t to√°n')\n",
    "    ax2.set_ylabel('Validation Accuracy (%)')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(algorithms)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # Th√™m gi√° tr·ªã l√™n c√°c c·ªôt\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    # 3. Loss evolution comparison\n",
    "    ax3 = axes[1, 0]\n",
    "    for alpha in [0.3, 0.9]:\n",
    "        for algorithm in ['FedAvg', 'FedProx', 'FedAdam']:\n",
    "            key = f\"{algorithm}_{alpha}\"\n",
    "            if key in data:\n",
    "                metrics = data[key]['metrics']\n",
    "                # Fix: Use safer data access with enumerate\n",
    "                rounds = [m.get('round', i+1) for i, m in enumerate(metrics)]\n",
    "                train_loss = [m['train_acc'] for m in metrics]\n",
    "\n",
    "                linestyle = '-' if alpha == 0.3 else '--'\n",
    "                ax3.plot(rounds, train_loss, linestyle,\n",
    "                       label=f'{algorithm} Œ±={alpha}',\n",
    "                       color=COLORS[algorithm], alpha=0.7)\n",
    "\n",
    "    ax3.set_title('So s√°nh Training Accuracy')\n",
    "    ax3.set_xlabel('Round')\n",
    "    ax3.set_ylabel('Training Accuracy')\n",
    "    ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_yscale('log')  # Log scale for better visualization\n",
    "\n",
    "    # T·∫°o legend handles ri√™ng\n",
    "    ax4 = axes[1, 1]\n",
    "\n",
    "\n",
    "    for algorithm in ['FedAvg', 'FedProx','FedAdam']:\n",
    "        for alpha in [0.3, 0.9]:\n",
    "            key = f\"{algorithm}_{alpha}\"\n",
    "            if key in data:\n",
    "                metrics = data[key]['metrics']\n",
    "                last_20 = metrics[-20:] if len(metrics) >= 20 else metrics\n",
    "                avg_val_acc = np.mean([m.get('val_acc', 0) for m in last_20]) * 100\n",
    "                total_time_seconds = sum([m.get('round_total_time', 0) for m in metrics])\n",
    "                total_time_hours = total_time_seconds / 3600\n",
    "\n",
    "                marker = 'o' if alpha == 0.3 else 's'\n",
    "                ax4.scatter(total_time_hours, avg_val_acc,\n",
    "                          color=COLORS[algorithm],\n",
    "                          s=100, marker=marker, alpha=0.8)\n",
    "\n",
    "                # Th√™m annotation v·ªõi bbox (khung ri√™ng)\n",
    "                ax4.annotate(f'{algorithm} Œ±={alpha}\\n{avg_val_acc:.2f}%, {total_time_hours:.2f}h',\n",
    "                            (total_time_hours, avg_val_acc),\n",
    "                            xytext=(10, 10), textcoords='offset points',\n",
    "                            fontsize=8,\n",
    "                            bbox=dict(boxstyle=\"round,pad=0.3\",\n",
    "                                    facecolor=COLORS[algorithm],\n",
    "                                    alpha=0.3,\n",
    "                                    edgecolor=COLORS[algorithm]),\n",
    "                            ha='left')\n",
    "    ax4.set_title('Th·ªùi gian v√† Accuracy')\n",
    "    ax4.set_xlabel('Th·ªùi gian (gi·ªù)')\n",
    "    ax4.set_ylabel('Validation Accuracy (%)')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'additional_analysis_{dataset_name.lower().replace(\"-\", \"_\")}.png',\n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ba54c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4713,
     "status": "ok",
     "timestamp": 1756103923419,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "c6ba54c0",
    "outputId": "84141180-318a-4176-9149-4e6544c24db9"
   },
   "outputs": [],
   "source": [
    "plot_additional_analysis(data, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nVVWqBMJsygy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "executionInfo": {
     "elapsed": 1296,
     "status": "ok",
     "timestamp": 1756103924725,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "nVVWqBMJsygy",
    "outputId": "39bc61c5-dec9-4a1c-8bb0-5d7537634e66"
   },
   "outputs": [],
   "source": [
    "def plot_additional_analysis(data, dataset_name=dataset_name):\n",
    "    \"\"\"5. C√°c bi·ªÉu ƒë·ªì ph√¢n t√≠ch b·ªï sung\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    fig.suptitle(f'T·ªëc ƒë·ªô h·ªôi t·ª• (Validation Accuracy) - {dataset_name}', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # 1. Convergence Rate (t·ªëc ƒë·ªô h·ªôi t·ª•)\n",
    "    ax1 = axes[0]\n",
    "    for alpha in [0.3]:\n",
    "        for algorithm in ['FedAvg', 'FedProx', 'FedAdam']:\n",
    "            key = f\"{algorithm}_{alpha}\"\n",
    "            if key in data:\n",
    "                metrics = data[key]['metrics']\n",
    "                val_acc = [m.get('val_acc', 0) * 100 for m in metrics]\n",
    "                # T√≠nh ƒë·ªô c·∫£i thi·ªán so v·ªõi round tr∆∞·ªõc (tr∆∞·ªõc - sau)\n",
    "                improvements = [val_acc[i] - val_acc[i-1] for i in range(1, len(val_acc))]\n",
    "                # Fix: Use safer data access with enumerate\n",
    "                rounds = [m.get('round', i+1) for i, m in enumerate(metrics[1:])]\n",
    "\n",
    "                linestyle = '-' if alpha == 0.3 else '--'\n",
    "                ax1.plot(rounds, improvements, linestyle,\n",
    "                       label=f'{algorithm} Œ±={alpha}',\n",
    "                       color=COLORS[algorithm], alpha=0.7)\n",
    "\n",
    "    ax1.set_title('Œ± = 0.3',fontsize=13, fontweight='bold')\n",
    "    ax1.set_xlabel('Round')\n",
    "    ax1.set_ylabel('C·∫£i thi·ªán Accuracy (%)')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "\n",
    "\n",
    "    ax2 = axes[1]\n",
    "    for alpha in [0.9]:\n",
    "        for algorithm in ['FedAvg', 'FedProx', 'FedAdam']:\n",
    "            key = f\"{algorithm}_{alpha}\"\n",
    "            if key in data:\n",
    "                metrics = data[key]['metrics']\n",
    "                val_acc = [m.get('val_acc', 0) * 100 for m in metrics]\n",
    "                # T√≠nh ƒë·ªô c·∫£i thi·ªán so v·ªõi round tr∆∞·ªõc\n",
    "                improvements = [val_acc[i] - val_acc[i-1] for i in range(1, len(val_acc))]\n",
    "                #\n",
    "                rounds = [m.get('round', i+1) for i, m in enumerate(metrics[1:])]\n",
    "                linestyle = '-' if alpha == 0.3 else '--'\n",
    "                ax2.plot(rounds, improvements, linestyle,\n",
    "                       label=f'{algorithm} Œ±={alpha}',\n",
    "                       color=COLORS[algorithm], alpha=0.7)\n",
    "\n",
    "    ax2.set_title('Œ± = 0.9',fontsize=13, fontweight='bold')\n",
    "    ax2.set_xlabel('Round')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.grid(True, alpha=0.3, )\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'additional_analysis_{dataset_name.lower().replace(\"-\", \"_\")}.png',\n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_additional_analysis(data, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29H-cyir0UnK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 994
    },
    "executionInfo": {
     "elapsed": 3233,
     "status": "ok",
     "timestamp": 1756103927962,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "29H-cyir0UnK",
    "outputId": "8a79bfbf-559d-4f86-8d8c-7004a2633104"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_additional_analysis(data, dataset_name=\"Dataset\"):\n",
    "    \"\"\"Ph√¢n t√≠ch tr·ª±c quan c√°c ch·ªâ s·ªë train/val accuracy & loss theo round\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(f'Ph√¢n t√≠ch chi ti·∫øt Accuracy v√† Loss - {dataset_name}', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # C√°c metric v√† subplot t∆∞∆°ng ·ª©ng\n",
    "    metrics_keys = [\n",
    "        (\"train_acc\", \"Training Accuracy\", axes[0, 0]),\n",
    "        (\"val_acc\", \"Validation Accuracy\", axes[1, 0]),\n",
    "        (\"train_loss\", \"Training Loss\", axes[0, 1]),\n",
    "        (\"val_loss\", \"Validation Loss\", axes[1, 1]),\n",
    "    ]\n",
    "\n",
    "    algorithms = ['FedAvg', 'FedProx', 'FedAdam']\n",
    "    alphas = [0.3, 0.9]\n",
    "\n",
    "    COLORS = {\n",
    "        'FedAdam': '#e74c3c',\n",
    "        'FedAvg': '#3498db',\n",
    "        'FedProx': '#27ae60'\n",
    "    }\n",
    "\n",
    "    for metric_key, title, ax in metrics_keys:\n",
    "        for alpha in alphas:\n",
    "            for algorithm in algorithms:\n",
    "                key = f\"{algorithm}_{alpha}\"\n",
    "                if key in data:\n",
    "                    metrics = data[key][\"metrics\"]\n",
    "                    if not metrics:\n",
    "                        continue\n",
    "\n",
    "                    rounds = [m.get(\"round\", i+1) for i, m in enumerate(metrics)]\n",
    "\n",
    "                    if \"acc\" in metric_key:\n",
    "                        # Accuracy: chuy·ªÉn v·ªÅ ph·∫ßn trƒÉm\n",
    "                        values = [m.get(metric_key, 0) * 100 for m in metrics]\n",
    "                    else:\n",
    "                        # Loss: gi·ªØ nguy√™n\n",
    "                        values = [m.get(metric_key, 0) for m in metrics]\n",
    "\n",
    "                    linestyle = '-' if alpha == 0.3 else '--'\n",
    "                    ax.plot(rounds, values, linestyle,\n",
    "                           label=f\"{algorithm} Œ±={alpha}\",\n",
    "                           color=COLORS[algorithm], alpha=0.8)\n",
    "\n",
    "        ax.set_title(title, fontsize=14)\n",
    "        ax.set_xlabel(\"Round\", fontsize=12)\n",
    "        ax.set_ylabel(\"Gi√° tr·ªã (%)\" if \"acc\" in metric_key else \"Loss\", fontsize=12)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if ax == axes[0, 0] or ax == axes[1, 0]:\n",
    "            ax.legend(loc='center right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'metrics_analysis_{dataset_name.lower().replace(\"-\", \"_\")}.png',\n",
    "               dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_additional_analysis(data, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f9e8a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1756103927969,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "0b8f9e8a"
   },
   "outputs": [],
   "source": [
    "def generate_conclusions(data, dataset_name=dataset_name):\n",
    "    \"\"\"T·∫°o k·∫øt lu·∫≠n t·ª´ d·ªØ li·ªáu\"\"\"\n",
    "    if not data:\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüîç K·∫æT LU·∫¨N V√Ä KHUY·∫æN NGH·ªä - {dataset_name}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # T√¨m thu·∫≠t to√°n t·ªët nh·∫•t theo t·ª´ng metric\n",
    "    best_acc = {'algorithm': '', 'alpha': 0, 'score': 0}\n",
    "    best_time = {'algorithm': '', 'alpha': 0, 'time': float('inf')}\n",
    "    best_convergence = {'algorithm': '', 'alpha': 0, 'final_acc': 0}\n",
    "\n",
    "    for key, data_item in data.items():\n",
    "        metrics = data_item['metrics']\n",
    "        last_20 = metrics[-20:] if len(metrics) >= 20 else metrics\n",
    "        avg_val_acc = np.mean([m.get('val_acc', 0) for m in last_20]) * 100\n",
    "        total_time = sum([m.get('round_total_time', 0) for m in metrics]) / 3600\n",
    "        final_acc = metrics[-1].get('val_acc', 0) * 100\n",
    "\n",
    "        if avg_val_acc > best_acc['score']:\n",
    "            best_acc = {'algorithm': data_item['algorithm'], 'alpha': data_item['alpha'], 'score': avg_val_acc}\n",
    "\n",
    "        if total_time < best_time['time']:\n",
    "            best_time = {'algorithm': data_item['algorithm'], 'alpha': data_item['alpha'], 'time': total_time}\n",
    "\n",
    "        if final_acc > best_convergence['final_acc']:\n",
    "            best_convergence = {'algorithm': data_item['algorithm'], 'alpha': data_item['alpha'], 'final_acc': final_acc}\n",
    "\n",
    "    print(f\"üèÜ Thu·∫≠t to√°n t·ªët nh·∫•t v·ªÅ Accuracy: {best_acc['algorithm']} (Œ±={best_acc['alpha']}) - {best_acc['score']:.2f}%\")\n",
    "    print(f\"‚ö° Thu·∫≠t to√°n nhanh nh·∫•t: {best_time['algorithm']} (Œ±={best_time['alpha']}) - {best_time['time']:.2f}h\")\n",
    "    print(f\"üéØ H·ªôi t·ª• t·ªët nh·∫•t: {best_convergence['algorithm']} (Œ±={best_convergence['alpha']}) - {best_convergence['final_acc']:.2f}%\")\n",
    "\n",
    "    # Ph√¢n t√≠ch ·∫£nh h∆∞·ªüng c·ªßa alpha\n",
    "    print(f\"\\nüìà PH√ÇN T√çCH ·∫¢NH H∆Ø·ªûNG C·ª¶A ALPHA:\")\n",
    "    for algorithm in ['FedAvg', 'FedProx', 'FedAdam']:\n",
    "        key_03 = f\"{algorithm}_0.3\"\n",
    "        key_09 = f\"{algorithm}_0.9\"\n",
    "\n",
    "        if key_03 in data and key_09 in data:\n",
    "            acc_03 = np.mean([m.get('val_acc', 0) for m in data[key_03]['metrics'][-20:]]) * 100\n",
    "            acc_09 = np.mean([m.get('val_acc', 0) for m in data[key_09]['metrics'][-20:]]) * 100\n",
    "            diff = acc_03 - acc_09\n",
    "\n",
    "            trend = f\"gi·∫£m {abs(diff):.2f}%\" if diff < 0 else f\"tƒÉng {diff:.2f}%\" if diff > 0 else \"kh√¥ng ƒë·ªïi\"\n",
    "            print(f\"  {algorithm}: ƒê·ªô ch√≠nh x√°c khi Œ±=0.3 so v·ªõi Œ±=0.9: {trend}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c8845",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1756103927980,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "204c8845",
    "outputId": "7d5b423e-7b61-4336-8db7-06520f88a66f"
   },
   "outputs": [],
   "source": [
    "# 4. K·∫øt lu·∫≠n v√† khuy·∫øn ngh·ªã\n",
    "generate_conclusions(data, dataset_name)\n",
    "\n",
    "print(f\"\\nüéâ HO√ÄN TH√ÄNH PH√ÇN T√çCH CHO {dataset_name}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K_6mlo2mkeAU",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1756103927986,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "K_6mlo2mkeAU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
