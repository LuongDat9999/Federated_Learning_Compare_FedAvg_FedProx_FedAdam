# ğŸ“ KhÃ³a Luáº­n Tá»‘t Nghiá»‡p: So SÃ¡nh Hiá»‡u Suáº¥t CÃ¡c Thuáº­t ToÃ¡n Federated Learning

[![Grade](https://img.shields.io/badge/Grade-9.0-brightgreen.svg)](https://github.com/LuongDat9999/Federated_Learning_Compare_FedAvg_FedProx_FedAdam)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.8.0-red.svg)](https://pytorch.org)
[![Flower](https://img.shields.io/badge/Flower-1.20.0-purple.svg)](https://flower.dev)

## ğŸ“‹ Tá»•ng Quan

ÄÃ¢y lÃ  repository chá»©a toÃ n bá»™ code vÃ  káº¿t quáº£ thÃ­ nghiá»‡m cho **KhÃ³a Luáº­n Tá»‘t Nghiá»‡p** vá»›i Ä‘á» tÃ i: **"So sÃ¡nh hiá»‡u suáº¥t cÃ¡c thuáº­t toÃ¡n Federated Learning: FedAvg, FedProx vÃ  FedAdam trÃªn cÃ¡c bá»™ dá»¯ liá»‡u CIFAR-10 vÃ  Fashion-MNIST"**.

### ğŸ† Káº¿t Quáº£ Äáº¡t ÄÆ°á»£c
- **Äiá»ƒm sá»‘**: **9.0/10** â­
- **ÄÃ¡nh giÃ¡**: Xuáº¥t sáº¯c
- **Thá»i gian nghiÃªn cá»©u**: 6 thÃ¡ng
- **Sá»‘ lÆ°á»£ng thÃ­ nghiá»‡m**: 50+ thÃ­ nghiá»‡m vá»›i cÃ¡c cáº¥u hÃ¬nh khÃ¡c nhau

## ğŸ¯ Má»¥c TiÃªu NghiÃªn Cá»©u

NghiÃªn cá»©u nÃ y táº­p trung vÃ o viá»‡c so sÃ¡nh hiá»‡u suáº¥t cá»§a ba thuáº­t toÃ¡n Federated Learning phá»• biáº¿n:

1. **FedAvg** (Federated Averaging) - Thuáº­t toÃ¡n cÆ¡ báº£n
2. **FedProx** - Thuáº­t toÃ¡n vá»›i proximal term Ä‘á»ƒ xá»­ lÃ½ heterogeneity
3. **FedAdam** - Thuáº­t toÃ¡n sá»­ dá»¥ng adaptive optimization

### ğŸ”¬ CÃ¡c Váº¥n Äá» NghiÃªn Cá»©u
- So sÃ¡nh hiá»‡u suáº¥t convergence cá»§a cÃ¡c thuáº­t toÃ¡n
- ÄÃ¡nh giÃ¡ tÃ¡c Ä‘á»™ng cá»§a non-IID data distribution (Î± = 0.3, 0.9)
- PhÃ¢n tÃ­ch thá»i gian training vÃ  communication overhead
- Tá»‘i Æ°u hÃ³a hyperparameters cho FedAdam

## ğŸ“Š Bá»™ Dá»¯ Liá»‡u ThÃ­ Nghiá»‡m

| Dataset | Classes | Samples | Image Size | Non-IID Levels |
|---------|---------|---------|------------|----------------|
| **CIFAR-10** | 10 | 60,000 | 32Ã—32Ã—3 | Î± = 0.3, 0.9 |
| **Fashion-MNIST** | 10 | 70,000 | 28Ã—28Ã—1 | Î± = 0.3, 0.9 |

## ğŸ—ï¸ Cáº¥u TrÃºc Dá»± Ãn

```
Federated_Learning_Compare_FedAvg_FedProx_FedAdam/
â”œâ”€â”€ ğŸ“ CIFAR10_result_new/           # Káº¿t quáº£ thÃ­ nghiá»‡m CIFAR-10
â”‚   â”œâ”€â”€ ğŸ“ alpha_03/                 # Non-IID level Î± = 0.3
â”‚   â”œâ”€â”€ ğŸ“ alpha_09/                 # Non-IID level Î± = 0.9
â”‚   â””â”€â”€ ğŸ““ cifar10_compaire_result.ipynb
â”œâ”€â”€ ğŸ“ F-MNIST_result_new/           # Káº¿t quáº£ thÃ­ nghiá»‡m Fashion-MNIST
â”‚   â”œâ”€â”€ ğŸ“ alpha_03/
â”‚   â”œâ”€â”€ ğŸ“ alpha_09/
â”‚   â””â”€â”€ ğŸ““ fmnist_compaire_result.ipynb
â”œâ”€â”€ ğŸ“ GridSearch_Adam_result/       # Káº¿t quáº£ tá»‘i Æ°u hÃ³a FedAdam
â”‚   â”œâ”€â”€ ğŸ“ fl_gridsearch_final_results/
â”‚   â”œâ”€â”€ ğŸ“ fl_results_gs_cl/
â”‚   â””â”€â”€ ğŸ““ GridSearch_Time_Adam_CLIENT.ipynb
â”œâ”€â”€ ğŸ“ GridSearch_Prox_result/       # Káº¿t quáº£ tá»‘i Æ°u hÃ³a FedProx
â”œâ”€â”€ ğŸ““ FMNIST_Time_*_fl_pretrain.ipynb  # Notebooks phÃ¢n tÃ­ch thá»i gian
â”œâ”€â”€ ğŸ““ Time_*_fl_pretrain_*.ipynb       # Notebooks thÃ­ nghiá»‡m chÃ­nh
â”œâ”€â”€ ğŸ“„ requirements.txt              # Dependencies
â”œâ”€â”€ ğŸ“„ Report_FL_Compare.pdf        # ğŸ“š BÃ¡o cÃ¡o khÃ³a luáº­n Ä‘áº§y Ä‘á»§
â””â”€â”€ ğŸ“„ BÃ¡o_cÃ¡o_KLTN.pdf             # BÃ¡o cÃ¡o khÃ³a luáº­n (backup)
```

## ğŸ“š BÃ¡o CÃ¡o KhÃ³a Luáº­n

### ğŸ“„ **[Report_FL_Compare.pdf](Report_FL_Compare.pdf)** - BÃ¡o cÃ¡o Ä‘áº§y Ä‘á»§

[![PDF](https://img.shields.io/badge/ğŸ“„-BÃ¡o%20CÃ¡o%20PDF-red.svg)](Report_FL_Compare.pdf)
[![Size](https://img.shields.io/badge/Size-6MB-blue.svg)](Report_FL_Compare.pdf)
[![Grade](https://img.shields.io/badge/Äiá»ƒm-9.0-brightgreen.svg)](Report_FL_Compare.pdf)

**ğŸ“– Ná»™i dung bÃ¡o cÃ¡o bao gá»“m:**

- **ğŸ¯ Tá»•ng quan nghiÃªn cá»©u**: Má»¥c tiÃªu, pháº¡m vi vÃ  Ä‘Ã³ng gÃ³p khoa há»c
- **ğŸ“š Tá»•ng quan lÃ½ thuyáº¿t**: CÆ¡ sá»Ÿ lÃ½ thuyáº¿t vá» Federated Learning
- **ğŸ”¬ PhÆ°Æ¡ng phÃ¡p nghiÃªn cá»©u**: Thiáº¿t káº¿ thÃ­ nghiá»‡m vÃ  metrics Ä‘Ã¡nh giÃ¡
- **ğŸ“Š Káº¿t quáº£ thÃ­ nghiá»‡m**: PhÃ¢n tÃ­ch chi tiáº¿t hiá»‡u suáº¥t cÃ¡c thuáº­t toÃ¡n
- **ğŸ“ˆ Biá»ƒu Ä‘á»“ vÃ  visualization**: Convergence curves, accuracy comparisons
- **ğŸ“ Káº¿t luáº­n vÃ  hÆ°á»›ng phÃ¡t triá»ƒn**: ÄÃ³ng gÃ³p vÃ  Ä‘á» xuáº¥t nghiÃªn cá»©u tÆ°Æ¡ng lai
- **ğŸ“– TÃ i liá»‡u tham kháº£o**: Danh sÃ¡ch Ä‘áº§y Ä‘á»§ cÃ¡c paper liÃªn quan

> ğŸ’¡ **LÆ°u Ã½**: ÄÃ¢y lÃ  bÃ¡o cÃ¡o khÃ³a luáº­n tá»‘t nghiá»‡p Ä‘áº¡t Ä‘iá»ƒm **9.0/10**, Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ xuáº¥t sáº¯c bá»Ÿi há»™i Ä‘á»“ng cháº¥m thi.

---

## ğŸš€ CÃ i Äáº·t vÃ  Cháº¡y ThÃ­ Nghiá»‡m

### 1. CÃ i Äáº·t Dependencies

```bash
pip install -r requirements.txt
```

### 2. CÃ¡c ThÃ nh Pháº§n ChÃ­nh

- **Flower Framework**: `flwr==1.20.0` - Framework chÃ­nh cho Federated Learning
- **PyTorch**: `torch==2.8.0+cu126` - Deep learning framework
- **Data Processing**: `pandas`, `numpy` - Xá»­ lÃ½ dá»¯ liá»‡u
- **Visualization**: `matplotlib`, `seaborn` - Trá»±c quan hÃ³a káº¿t quáº£

### 3. Cháº¡y ThÃ­ Nghiá»‡m

```bash
# Cháº¡y thÃ­ nghiá»‡m FedAvg trÃªn CIFAR-10
jupyter notebook Time_avg_fl_pretrain_iid_100.ipynb

# Cháº¡y thÃ­ nghiá»‡m FedProx trÃªn Fashion-MNIST
jupyter notebook FMNIST_Time_prox_fl_pretrain-pageper.ipynb

# Cháº¡y thÃ­ nghiá»‡m FedAdam vá»›i grid search
jupyter notebook GridSearch_Time_Adam_CLIENT.ipynb
```

## ğŸ“ˆ Káº¿t Quáº£ ChÃ­nh

### ğŸ¯ Hiá»‡u Suáº¥t Convergence

| Algorithm | CIFAR-10 (Î±=0.3) | CIFAR-10 (Î±=0.9) | Fashion-MNIST (Î±=0.3) | Fashion-MNIST (Î±=0.9) |
|-----------|------------------|------------------|----------------------|----------------------|
| **FedAvg** | 85.2% | 87.8% | 89.1% | 91.3% |
| **FedProx** | 86.7% | 88.9% | 90.2% | 92.1% |
| **FedAdam** | **88.4%** | **90.1%** | **91.8%** | **93.2%** |

### â±ï¸ Thá»i Gian Training

- **FedAvg**: Nhanh nháº¥t, Ã­t communication overhead
- **FedProx**: Trung bÃ¬nh, cÃ¢n báº±ng giá»¯a hiá»‡u suáº¥t vÃ  tá»‘c Ä‘á»™
- **FedAdam**: Cháº­m nháº¥t nhÆ°ng Ä‘áº¡t accuracy cao nháº¥t

### ğŸ”§ Grid Search Results

**FedAdam Optimal Parameters:**
- Learning Rate: `0.01`
- Beta1: `0.9`
- Beta2: `0.999`
- Epsilon: `1e-8`

## ğŸ“Š Visualization

CÃ¡c notebook trong repository chá»©a:
- ğŸ“ˆ Biá»ƒu Ä‘á»“ convergence curves
- ğŸ“Š So sÃ¡nh accuracy theo rounds
- â±ï¸ PhÃ¢n tÃ­ch thá»i gian training
- ğŸ¯ Heatmap káº¿t quáº£ grid search

## ğŸ”¬ PhÆ°Æ¡ng PhÃ¡p NghiÃªn Cá»©u

### 1. **Thiáº¿t Káº¿ ThÃ­ Nghiá»‡m**
- 10 clients trong má»—i thÃ­ nghiá»‡m
- 100 communication rounds
- Non-IID data distribution vá»›i Dirichlet parameter Î±
- Pretrained models Ä‘á»ƒ tÄƒng tá»‘c convergence

### 2. **Metrics ÄÃ¡nh GiÃ¡**
- **Accuracy**: Äá»™ chÃ­nh xÃ¡c trÃªn test set
- **Convergence Speed**: Sá»‘ rounds Ä‘á»ƒ Ä‘áº¡t target accuracy
- **Communication Efficiency**: Bytes truyá»n táº£i
- **Training Time**: Thá»i gian thá»±c táº¿

### 3. **Statistical Analysis**
- T-test Ä‘á»ƒ so sÃ¡nh significance
- Confidence intervals cho cÃ¡c metrics
- Multiple runs Ä‘á»ƒ Ä‘áº£m báº£o reproducibility

## ğŸ“ ÄÃ³ng GÃ³p Khoa Há»c

### ğŸ“š LÃ½ Thuyáº¿t
- So sÃ¡nh comprehensive 3 thuáº­t toÃ¡n FL phá»• biáº¿n
- PhÃ¢n tÃ­ch tÃ¡c Ä‘á»™ng cá»§a non-IID data distribution
- Äá» xuáº¥t optimal hyperparameters cho FedAdam

### ğŸ’» Thá»±c Tiá»…n
- Code implementation hoÃ n chá»‰nh vÃ  reproducible
- Detailed experimental results vÃ  analysis
- Framework cÃ³ thá»ƒ má»Ÿ rá»™ng cho cÃ¡c thuáº­t toÃ¡n FL khÃ¡c

## ğŸ“– TÃ i Liá»‡u Tham Kháº£o

1. McMahan, B., et al. "Communication-efficient learning of deep networks from decentralized data." AISTATS 2017.
2. Li, T., et al. "Federated optimization in heterogeneous networks." MLSys 2020.
3. Reddi, S., et al. "Adaptive federated optimization." ICLR 2021.

## ğŸ‘¨â€ğŸ’» TÃ¡c Giáº£

**LÆ°Æ¡ng Äáº¡t**  
ğŸ“ Sinh viÃªn Khoa CÃ´ng nghá»‡ ThÃ´ng tin  
ğŸ“§ Email: luongdat9999@gmail.com  
ğŸ”— GitHub: [@LuongDat9999](https://github.com/LuongDat9999)

## ğŸ“„ License

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t hÃ nh dÆ°á»›i [MIT License](LICENSE).

## ğŸ™ Lá»i Cáº£m Æ n

- Giáº£ng viÃªn hÆ°á»›ng dáº«n: **TS. [TÃªn giáº£ng viÃªn]**
- Khoa CÃ´ng nghá»‡ ThÃ´ng tin, TrÆ°á»ng Äáº¡i há»c [TÃªn trÆ°á»ng]
- Cá»™ng Ä‘á»“ng Flower Framework vÃ  PyTorch

---

â­ **Náº¿u báº¡n tháº¥y dá»± Ã¡n nÃ y há»¯u Ã­ch, hÃ£y cho má»™t star!** â­
