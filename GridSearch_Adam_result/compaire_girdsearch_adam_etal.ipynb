{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d5f17",
   "metadata": {
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1754144011212,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "619d5f17"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31teUeNsI4hS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24196,
     "status": "ok",
     "timestamp": 1754144177057,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "31teUeNsI4hS",
    "outputId": "f3cae33d-ae75-4c70-d19a-16737fa00330"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8357e6ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "executionInfo": {
     "elapsed": 984,
     "status": "ok",
     "timestamp": 1754144335232,
     "user": {
      "displayName": "L∆∞∆°ng ƒê·∫°t",
      "userId": "11214560588962627512"
     },
     "user_tz": -420
    },
    "id": "8357e6ed",
    "outputId": "c5ef0e71-23fc-4183-8157-57187ba353b7"
   },
   "outputs": [],
   "source": [
    "root_path = '/content/drive/MyDrive/Colab Notebooks/Federated Learning/Final_code/GridSearch_Adam_result/'\n",
    "# ƒê·ªãnh nghƒ©a c√°c file JSON\n",
    "eta_files = {\n",
    "    0.1: root_path + \"fl_results_gs_cl/FedAdam_LR_0_1.json\",\n",
    "    0.01: root_path +\"fl_results_gs_cl/FedAdam_LR_0_01.json\",\n",
    "    0.001: root_path +\"fl_results_gs_cl/FedAdam_LR_0_001.json\",\n",
    "    0.03162: root_path +\"fl_results_gs_cl/FedAdam_LR_0_003162.json\",\n",
    "    0.003981: root_path +\"fl_results_gs_cl/FedAdam_LR_0_003981.json\"\n",
    "}\n",
    "# Load d·ªØ li·ªáu t·ª´ c√°c file JSON\n",
    "results = {}\n",
    "for eta, file_path in eta_files.items():\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            results[eta] = data\n",
    "        print(f\"ƒê√£ load th√†nh c√¥ng file {file_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Kh√¥ng t√¨m th·∫•y file {file_path}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"L·ªói khi parse JSON file {file_path}\")\n",
    "\n",
    "# T√≠nh to√°n c√°c metrics\n",
    "analysis_data = []\n",
    "for eta in results.keys():\n",
    "    metrics = results[eta]['metrics']\n",
    "\n",
    "    # Final validation accuracy (trung b√¨nh 10 round cu·ªëi)\n",
    "    val_accs = [round_data['val_acc'] for round_data in metrics]\n",
    "    last_10_val_accs = val_accs[-10:]\n",
    "    final_val_acc = np.mean(last_10_val_accs)\n",
    "\n",
    "    # Best validation accuracy (cao nh·∫•t trong t·∫•t c·∫£ rounds)\n",
    "    best_val_acc = max(val_accs)\n",
    "\n",
    "    # Convergence stability (ƒë·ªô l·ªách chu·∫©n c·ªßa validation accuracy trong 10 rounds cu·ªëi)\n",
    "    convergence_stability = np.std(last_10_val_accs)\n",
    "\n",
    "    analysis_data.append({\n",
    "        'eta': eta,\n",
    "        'final_val_acc': final_val_acc,\n",
    "        'best_val_acc': best_val_acc,\n",
    "        'convergence_stability': convergence_stability\n",
    "    })\n",
    "\n",
    "# S·∫Øp x·∫øp theo eta\n",
    "analysis_data.sort(key=lambda x: x['eta'])\n",
    "\n",
    "# T√¨m eta t·ªët nh·∫•t d·ª±a tr√™n final validation accuracy\n",
    "best_eta = max(analysis_data, key=lambda x: x['final_val_acc'])['eta']\n",
    "\n",
    "# T·∫°o bi·ªÉu ƒë·ªì t∆∞∆°ng t·ª± nh∆∞ trong h√¨nh\n",
    "plt.style.use('default')\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "etas = [data['eta'] for data in analysis_data]\n",
    "final_val_accs = [data['final_val_acc'] for data in analysis_data]\n",
    "best_val_accs = [data['best_val_acc'] for data in analysis_data]\n",
    "convergence_stabilities = [data['convergence_stability'] for data in analysis_data]\n",
    "\n",
    "# 1. Final Validation Accuracy vs Œ∑ (trung b√¨nh 10 round cu·ªëi)\n",
    "ax1.plot(etas, final_val_accs, 'o-', color='blue', linewidth=2, markersize=8, label='Final Val Acc (Avg 10)')\n",
    "ax1.axvline(x=best_eta, color='red', linestyle='--', linewidth=2, label=f'Best Œ∑={best_eta}')\n",
    "ax1.set_title('Final Validation Accuracy vs Œ∑ (Avg Last 10 Rounds)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Œ∑ (Learning Rate)', fontsize=12)\n",
    "ax1.set_ylabel('Final Validation Accuracy (Avg)', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Th√™m gi√° tr·ªã tr√™n ƒëi·ªÉm\n",
    "for i, (eta, acc) in enumerate(zip(etas, final_val_accs)):\n",
    "    ax1.annotate(f'{acc:.3f}', (eta, acc), textcoords=\"offset points\",\n",
    "                xytext=(0,10), ha='center', fontsize=10)\n",
    "\n",
    "# 2. Best Validation Accuracy vs Œ∑\n",
    "ax2.plot(etas, best_val_accs, 'o-', color='green', linewidth=2, markersize=8, label='Best Val Acc')\n",
    "ax2.axvline(x=best_eta, color='red', linestyle='--', linewidth=2, label=f'Best Œ∑={best_eta}')\n",
    "ax2.set_title('Best Validation Accuracy vs Œ∑', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Œ∑ (Learning Rate)', fontsize=12)\n",
    "ax2.set_ylabel('Best Validation Accuracy', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "# Th√™m gi√° tr·ªã tr√™n ƒëi·ªÉm\n",
    "for i, (eta, acc) in enumerate(zip(etas, best_val_accs)):\n",
    "    ax2.annotate(f'{acc:.3f}', (eta, acc), textcoords=\"offset points\",\n",
    "                xytext=(0,10), ha='center', fontsize=10)\n",
    "\n",
    "# 3. Convergence Stability vs Œ∑\n",
    "ax3.plot(etas, convergence_stabilities, 'o-', color='red', linewidth=2, markersize=8, label='Convergence Stability')\n",
    "ax3.axvline(x=best_eta, color='red', linestyle='--', linewidth=2, label=f'Best Œ∑={best_eta}')\n",
    "ax3.set_title('Convergence Stability vs Œ∑', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Œ∑ (Learning Rate)', fontsize=12)\n",
    "ax3.set_ylabel('Convergence Stability (Std)', fontsize=12)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend()\n",
    "\n",
    "# Th√™m gi√° tr·ªã tr√™n ƒëi·ªÉm\n",
    "for i, (eta, stability) in enumerate(zip(etas, convergence_stabilities)):\n",
    "    ax3.annotate(f'{stability:.3f}', (eta, stability), textcoords=\"offset points\",\n",
    "                xytext=(0,10), ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# In b·∫£ng t·ªïng k·∫øt\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"PH√ÇN T√çCH K·∫æT QU·∫¢ FEDADAM THEO THAM S·ªê Œ∑\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "summary_df = pd.DataFrame(analysis_data)\n",
    "summary_df.columns = ['Œ∑ (Learning Rate)', 'Final Val Acc (Avg 10)', 'Best Val Acc', 'Convergence Stability (Std)']\n",
    "print(summary_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "print(f\"\\nüéØ ETA T·ªêT NH·∫§T (d·ª±a tr√™n Final Validation Accuracy - trung b√¨nh 10 round cu·ªëi): Œ∑ = {best_eta}\")\n",
    "best_data = next(data for data in analysis_data if data['eta'] == best_eta)\n",
    "print(f\"   Final Validation Accuracy (Avg 10): {best_data['final_val_acc']:.4f}\")\n",
    "print(f\"   Best Validation Accuracy: {best_data['best_val_acc']:.4f}\")\n",
    "print(f\"   Convergence Stability: {best_data['convergence_stability']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1984d086",
   "metadata": {
    "id": "1984d086",
    "outputId": "ccd38a92-337e-4d13-978f-fed11bb199b0"
   },
   "outputs": [],
   "source": [
    "# T·∫°o bi·ªÉu ƒë·ªì b·ªï sung: Training v√† Validation curves cho t·∫•t c·∫£ eta\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Training v√† Validation Curves cho FedAdam v·ªõi c√°c Œ∑ kh√°c nhau', fontsize=16, fontweight='bold')\n",
    "\n",
    "# T·∫°o colors dictionary ƒë·ªông d·ª±a tr√™n s·ªë l∆∞·ª£ng eta\n",
    "eta_list = sorted(results.keys())\n",
    "colors_list = ['blue', 'red', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
    "colors = {eta: colors_list[i % len(colors_list)] for i, eta in enumerate(eta_list)}\n",
    "\n",
    "# Training Loss\n",
    "ax1 = axes[0, 0]\n",
    "for eta in results.keys():\n",
    "    metrics = results[eta]['metrics']\n",
    "    rounds = [round_data['round'] for round_data in metrics]\n",
    "    train_losses = [round_data['train_loss'] for round_data in metrics]\n",
    "    ax1.plot(rounds, train_losses, label=f'Œ∑ = {eta}', color=colors[eta], linewidth=2)\n",
    "\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.set_xlabel('Round')\n",
    "ax1.set_ylabel('Training Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Validation Loss\n",
    "ax2 = axes[0, 1]\n",
    "for eta in results.keys():\n",
    "    metrics = results[eta]['metrics']\n",
    "    rounds = [round_data['round'] for round_data in metrics]\n",
    "    val_losses = [round_data['val_loss'] for round_data in metrics]\n",
    "    ax2.plot(rounds, val_losses, label=f'Œ∑ = {eta}', color=colors[eta], linewidth=2)\n",
    "\n",
    "ax2.set_title('Validation Loss')\n",
    "ax2.set_xlabel('Round')\n",
    "ax2.set_ylabel('Validation Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Training Accuracy\n",
    "ax3 = axes[1, 0]\n",
    "for eta in results.keys():\n",
    "    metrics = results[eta]['metrics']\n",
    "    rounds = [round_data['round'] for round_data in metrics]\n",
    "    train_accs = [round_data['train_acc'] for round_data in metrics]\n",
    "    ax3.plot(rounds, train_accs, label=f'Œ∑ = {eta}', color=colors[eta], linewidth=2)\n",
    "\n",
    "ax3.set_title('Training Accuracy')\n",
    "ax3.set_xlabel('Round')\n",
    "ax3.set_ylabel('Training Accuracy')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Validation Accuracy\n",
    "ax4 = axes[1, 1]\n",
    "for eta in results.keys():\n",
    "    metrics = results[eta]['metrics']\n",
    "    rounds = [round_data['round'] for round_data in metrics]\n",
    "    val_accs = [round_data['val_acc'] for round_data in metrics]\n",
    "    ax4.plot(rounds, val_accs, label=f'Œ∑ = {eta}', color=colors[eta], linewidth=2)\n",
    "\n",
    "ax4.set_title('Validation Accuracy')\n",
    "ax4.set_xlabel('Round')\n",
    "ax4.set_ylabel('Validation Accuracy')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f71195d",
   "metadata": {
    "id": "5f71195d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
